{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "844b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunthshah/Desktop/Crypto-Price-Moevement-Prediction/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "2575f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_Price</th>\n",
       "      <th>Close_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_10_lag_1</th>\n",
       "      <th>MA_10_lag_2</th>\n",
       "      <th>MA_10_lag_3</th>\n",
       "      <th>MA_10_lag_4</th>\n",
       "      <th>MA_10_lag_5</th>\n",
       "      <th>MA_10_lag_6</th>\n",
       "      <th>MA_10_lag_7</th>\n",
       "      <th>MA_10_lag_8</th>\n",
       "      <th>Momentum_ratios</th>\n",
       "      <th>Sentiment_deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>59097.295565</td>\n",
       "      <td>59029.726208</td>\n",
       "      <td>59900.004347</td>\n",
       "      <td>58784.035582</td>\n",
       "      <td>-67.569357</td>\n",
       "      <td>4462601</td>\n",
       "      <td>49045.482581</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>33.144940</td>\n",
       "      <td>...</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.898218</td>\n",
       "      <td>0.294423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>54973.279224</td>\n",
       "      <td>55151.317602</td>\n",
       "      <td>55396.713428</td>\n",
       "      <td>54378.735255</td>\n",
       "      <td>178.038378</td>\n",
       "      <td>9775141</td>\n",
       "      <td>48852.372428</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>43.650581</td>\n",
       "      <td>...</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934297</td>\n",
       "      <td>-1.048490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>36370.173320</td>\n",
       "      <td>36497.900856</td>\n",
       "      <td>36938.992350</td>\n",
       "      <td>36371.219308</td>\n",
       "      <td>127.727536</td>\n",
       "      <td>5726515</td>\n",
       "      <td>46570.552431</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44.739048</td>\n",
       "      <td>...</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661777</td>\n",
       "      <td>-1.083444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>35454.749016</td>\n",
       "      <td>35059.052567</td>\n",
       "      <td>35211.603012</td>\n",
       "      <td>34107.853810</td>\n",
       "      <td>-395.696449</td>\n",
       "      <td>4617507</td>\n",
       "      <td>43367.089528</td>\n",
       "      <td>43805.992068</td>\n",
       "      <td>37.650721</td>\n",
       "      <td>...</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960577</td>\n",
       "      <td>-1.199126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>35502.135296</td>\n",
       "      <td>35750.062833</td>\n",
       "      <td>36428.171405</td>\n",
       "      <td>35625.323065</td>\n",
       "      <td>247.927537</td>\n",
       "      <td>4181273</td>\n",
       "      <td>44297.612013</td>\n",
       "      <td>43903.552042</td>\n",
       "      <td>39.993981</td>\n",
       "      <td>...</td>\n",
       "      <td>43805.992068</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019710</td>\n",
       "      <td>0.543907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open_Price   Close_Price    High_Price     Low_Price  \\\n",
       "0  2023-01-12  59097.295565  59029.726208  59900.004347  58784.035582   \n",
       "1  2023-01-13  54973.279224  55151.317602  55396.713428  54378.735255   \n",
       "2  2023-01-14  36370.173320  36497.900856  36938.992350  36371.219308   \n",
       "3  2023-01-15  35454.749016  35059.052567  35211.603012  34107.853810   \n",
       "4  2023-01-16  35502.135296  35750.062833  36428.171405  35625.323065   \n",
       "\n",
       "   Price_Change   Volume          MA_5         MA_10        RSI  ...  \\\n",
       "0    -67.569357  4462601  49045.482581  44580.256718  33.144940  ...   \n",
       "1    178.038378  9775141  48852.372428  44929.860092  43.650581  ...   \n",
       "2    127.727536  5726515  46570.552431  43760.010546  44.739048  ...   \n",
       "3   -395.696449  4617507  43367.089528  43805.992068  37.650721  ...   \n",
       "4    247.927537  4181273  44297.612013  43903.552042  39.993981  ...   \n",
       "\n",
       "    MA_10_lag_1   MA_10_lag_2   MA_10_lag_3   MA_10_lag_4   MA_10_lag_5  \\\n",
       "0  44528.878721  45577.477694      0.000000      0.000000      0.000000   \n",
       "1  44580.256718  44528.878721  45577.477694      0.000000      0.000000   \n",
       "2  44929.860092  44580.256718  44528.878721  45577.477694      0.000000   \n",
       "3  43760.010546  44929.860092  44580.256718  44528.878721  45577.477694   \n",
       "4  43805.992068  43760.010546  44929.860092  44580.256718  44528.878721   \n",
       "\n",
       "    MA_10_lag_6  MA_10_lag_7  MA_10_lag_8  Momentum_ratios  Sentiment_deltas  \n",
       "0      0.000000          0.0          0.0         1.898218          0.294423  \n",
       "1      0.000000          0.0          0.0         0.934297         -1.048490  \n",
       "2      0.000000          0.0          0.0         0.661777         -1.083444  \n",
       "3      0.000000          0.0          0.0         0.960577         -1.199126  \n",
       "4  45577.477694          0.0          0.0         1.019710          0.543907  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/crypto_price_movement_dataset_with_lags.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellUniqueIdByVincent": "f55a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (34982, 10, 9) (34982,) (7488, 10, 9) (7488,) (7489, 10, 9) (7489,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Split raw DataFrame by time (70/15/15)\n",
    "n = len(df)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = train_end + int(n * 0.15)\n",
    "\n",
    "train_df = df.iloc[:train_end].copy()\n",
    "val_df   = df.iloc[train_end:val_end].copy()\n",
    "test_df  = df.iloc[val_end:].copy()\n",
    "\n",
    "# 2. Identify feature columns (exclude Date, target, and any leakage features)\n",
    "feature_cols = [\n",
    "    'Close_Price','Global_Economy','High_Price','Low_Price',\n",
    "    'MA_10','MA_10_lag_2','Open_Price','RSI','Volatility'\n",
    "    # add any engineered features here\n",
    "]\n",
    "\n",
    "# 3. Fit scaler on TRAIN only, then transform all splits\n",
    "scaler = StandardScaler()\n",
    "train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "val_df[feature_cols]   = scaler.transform(val_df[feature_cols])\n",
    "test_df[feature_cols]  = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "# 4. Function to build time‑windows\n",
    "def create_time_windows(df, feature_cols, window_size=10):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(df)):\n",
    "        X.append(df[feature_cols].iloc[i-window_size:i].values)\n",
    "        y.append(df['Price_Movement'].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 5. Create windowed datasets\n",
    "window_size = 10\n",
    "X_train, y_train = create_time_windows(train_df, feature_cols, window_size)\n",
    "X_val,   y_val   = create_time_windows(val_df,   feature_cols, window_size)\n",
    "X_test,  y_test  = create_time_windows(test_df,  feature_cols, window_size)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      X_train.shape, y_train.shape,\n",
    "      X_val.shape,   y_val.shape,\n",
    "      X_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "3a2f2"
   },
   "source": [
    "# Attention on top of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "40f97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,944</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ permute_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,944\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │     \u001b[38;5;34m12,416\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │        \u001b[38;5;34m110\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ permute_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,399</span> (126.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,399\u001b[0m (126.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,207</span> (125.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,207\u001b[0m (125.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, BatchNormalization, \n",
    "    Permute, Multiply, Lambda, Softmax, Concatenate\n",
    ")\n",
    "\n",
    "def attention_block(inputs):\n",
    "    # inputs.shape = (batch, timesteps, features)\n",
    "    # 1) Learn a score for each timestep\n",
    "    a = Permute((2,1))(inputs)                       # (batch, features, timesteps)\n",
    "    a = Dense(inputs.shape[1], activation='tanh')(a) # (batch, features, timesteps)\n",
    "    a = Softmax(axis=-1)(a)                          # normalize over timesteps\n",
    "    a_probs = Permute((2,1))(a)                      # (batch, timesteps, features)\n",
    "    # 2) Weight the inputs\n",
    "    output = Multiply()([inputs, a_probs])           # (batch, timesteps, features)\n",
    "    # 3) Sum across time\n",
    "    return Lambda(lambda x: tf.reduce_sum(x, axis=1))(output)\n",
    "\n",
    "def create_lstm_with_attention(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    \n",
    "    x = LSTM(64, return_sequences=True)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention pooling\n",
    "    x = attention_block(x)   # (batch, features)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_attn = create_lstm_with_attention(X_train.shape[1], X_train.shape[2])\n",
    "model_attn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellUniqueIdByVincent": "1cb86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 5s - 8ms/step - AUC: 0.5009 - accuracy: 0.5023 - loss: 0.6932 - val_AUC: 0.4917 - val_accuracy: 0.4959 - val_loss: 0.6934 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5046 - accuracy: 0.5046 - loss: 0.6931 - val_AUC: 0.5033 - val_accuracy: 0.4977 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5002 - accuracy: 0.5015 - loss: 0.6932 - val_AUC: 0.5069 - val_accuracy: 0.4981 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.4945 - accuracy: 0.5028 - loss: 0.6932 - val_AUC: 0.5003 - val_accuracy: 0.4988 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5003 - accuracy: 0.5034 - loss: 0.6931 - val_AUC: 0.5015 - val_accuracy: 0.4979 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5026 - accuracy: 0.5030 - loss: 0.6931 - val_AUC: 0.5020 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.4977 - accuracy: 0.5044 - loss: 0.6932 - val_AUC: 0.4982 - val_accuracy: 0.4931 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5035 - accuracy: 0.5045 - loss: 0.6931 - val_AUC: 0.4885 - val_accuracy: 0.4949 - val_loss: 0.6933 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.4995 - accuracy: 0.5011 - loss: 0.6931 - val_AUC: 0.5047 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5009 - accuracy: 0.5042 - loss: 0.6931 - val_AUC: 0.5005 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.4950 - accuracy: 0.5032 - loss: 0.6931 - val_AUC: 0.4999 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5021 - accuracy: 0.5048 - loss: 0.6931 - val_AUC: 0.5009 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5023 - accuracy: 0.5040 - loss: 0.6931 - val_AUC: 0.5028 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5055 - accuracy: 0.5038 - loss: 0.6930 - val_AUC: 0.5061 - val_accuracy: 0.4981 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5052 - accuracy: 0.5037 - loss: 0.6929 - val_AUC: 0.5006 - val_accuracy: 0.4983 - val_loss: 0.6934 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5019 - accuracy: 0.5045 - loss: 0.6930 - val_AUC: 0.5003 - val_accuracy: 0.4983 - val_loss: 0.6933 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5037 - accuracy: 0.5031 - loss: 0.6930 - val_AUC: 0.5050 - val_accuracy: 0.4983 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5066 - accuracy: 0.5044 - loss: 0.6929 - val_AUC: 0.5058 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5077 - accuracy: 0.5045 - loss: 0.6927 - val_AUC: 0.5036 - val_accuracy: 0.5007 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5083 - accuracy: 0.5065 - loss: 0.6929 - val_AUC: 0.5068 - val_accuracy: 0.5019 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5079 - accuracy: 0.5047 - loss: 0.6928 - val_AUC: 0.4990 - val_accuracy: 0.4993 - val_loss: 0.6932 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5089 - accuracy: 0.5084 - loss: 0.6929 - val_AUC: 0.5026 - val_accuracy: 0.5033 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5111 - accuracy: 0.5066 - loss: 0.6928 - val_AUC: 0.5098 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5128 - accuracy: 0.5065 - loss: 0.6926 - val_AUC: 0.5063 - val_accuracy: 0.4984 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5080 - accuracy: 0.5045 - loss: 0.6927 - val_AUC: 0.5050 - val_accuracy: 0.4979 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5122 - accuracy: 0.5071 - loss: 0.6926 - val_AUC: 0.5088 - val_accuracy: 0.5012 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5077 - loss: 0.6926 - val_AUC: 0.5074 - val_accuracy: 0.4964 - val_loss: 0.6930 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5131 - accuracy: 0.5067 - loss: 0.6923 - val_AUC: 0.5098 - val_accuracy: 0.5028 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5155 - accuracy: 0.5089 - loss: 0.6925 - val_AUC: 0.5065 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 6.2500e-05\n",
      "Epoch 30/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5097 - loss: 0.6925 - val_AUC: 0.5072 - val_accuracy: 0.4971 - val_loss: 0.6931 - learning_rate: 6.2500e-05\n",
      "Epoch 31/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5138 - accuracy: 0.5076 - loss: 0.6924 - val_AUC: 0.5059 - val_accuracy: 0.4977 - val_loss: 0.6929 - learning_rate: 6.2500e-05\n",
      "Epoch 32/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5121 - accuracy: 0.5064 - loss: 0.6924 - val_AUC: 0.5063 - val_accuracy: 0.4985 - val_loss: 0.6930 - learning_rate: 6.2500e-05\n",
      "Epoch 33/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5142 - accuracy: 0.5075 - loss: 0.6924 - val_AUC: 0.5055 - val_accuracy: 0.4983 - val_loss: 0.6930 - learning_rate: 6.2500e-05\n",
      "Epoch 34/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5121 - accuracy: 0.5072 - loss: 0.6925 - val_AUC: 0.5066 - val_accuracy: 0.4993 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 35/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5153 - accuracy: 0.5129 - loss: 0.6923 - val_AUC: 0.5040 - val_accuracy: 0.5019 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 36/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5131 - accuracy: 0.5069 - loss: 0.6922 - val_AUC: 0.5046 - val_accuracy: 0.5001 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "75c31"
   },
   "source": [
    "# CNN with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "f3ed7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,345</span> (67.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,345\u001b[0m (67.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,089</span> (66.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,089\u001b[0m (66.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "def create_cnn_lstm(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    \n",
    "    # Convolutional front‑end\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # LSTM back‑end\n",
    "    x = LSTM(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_cnn_lstm = create_cnn_lstm(X_train.shape[1], X_train.shape[2])\n",
    "model_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellUniqueIdByVincent": "28b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 6ms/step - AUC: 0.5104 - accuracy: 0.5056 - loss: 0.6925 - val_AUC: 0.5072 - val_accuracy: 0.5011 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 2/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5106 - accuracy: 0.5051 - loss: 0.6926 - val_AUC: 0.5096 - val_accuracy: 0.5001 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5139 - accuracy: 0.5102 - loss: 0.6926 - val_AUC: 0.5098 - val_accuracy: 0.4975 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5148 - accuracy: 0.5083 - loss: 0.6924 - val_AUC: 0.5107 - val_accuracy: 0.4977 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 5/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5104 - accuracy: 0.5067 - loss: 0.6927 - val_AUC: 0.5123 - val_accuracy: 0.4980 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5114 - accuracy: 0.5060 - loss: 0.6925 - val_AUC: 0.5097 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 7/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5115 - accuracy: 0.5043 - loss: 0.6924 - val_AUC: 0.5090 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5135 - accuracy: 0.5069 - loss: 0.6925 - val_AUC: 0.5087 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5149 - accuracy: 0.5087 - loss: 0.6924 - val_AUC: 0.5078 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5112 - accuracy: 0.5075 - loss: 0.6925 - val_AUC: 0.5082 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5135 - accuracy: 0.5088 - loss: 0.6924 - val_AUC: 0.5082 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5136 - accuracy: 0.5087 - loss: 0.6925 - val_AUC: 0.5098 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 13/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5151 - accuracy: 0.5098 - loss: 0.6924 - val_AUC: 0.5087 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 14/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5130 - accuracy: 0.5083 - loss: 0.6923 - val_AUC: 0.5089 - val_accuracy: 0.4993 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 15/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5147 - accuracy: 0.5057 - loss: 0.6925 - val_AUC: 0.5081 - val_accuracy: 0.5001 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 16/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5182 - accuracy: 0.5101 - loss: 0.6923 - val_AUC: 0.5078 - val_accuracy: 0.5003 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 17/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5154 - accuracy: 0.5113 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4995 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 18/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5134 - accuracy: 0.5078 - loss: 0.6924 - val_AUC: 0.5105 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 19/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5158 - accuracy: 0.5109 - loss: 0.6922 - val_AUC: 0.5079 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9a606"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellUniqueIdByVincent": "fc3b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m88,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,953</span> (351.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,953\u001b[0m (351.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,953</span> (351.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,953\u001b[0m (351.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install keras-tcn if needed: pip install keras-tcn\n",
    "from tcn import TCN\n",
    "\n",
    "def create_tcn(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    x = TCN(nb_filters=64, kernel_size=3, dilations=[1,2,4,8],\n",
    "            return_sequences=False, activation='relu')(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_tcn = create_tcn(X_train.shape[1], X_train.shape[2])\n",
    "model_tcn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellUniqueIdByVincent": "1476e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 6ms/step - AUC: 0.5129 - accuracy: 0.5103 - loss: 0.6922 - val_AUC: 0.5074 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5166 - accuracy: 0.5111 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4980 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 3/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5144 - accuracy: 0.5081 - loss: 0.6924 - val_AUC: 0.5087 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5096 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 5/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5147 - accuracy: 0.5085 - loss: 0.6925 - val_AUC: 0.5075 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 6/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5161 - accuracy: 0.5080 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 7/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5171 - accuracy: 0.5131 - loss: 0.6923 - val_AUC: 0.5091 - val_accuracy: 0.4991 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5145 - accuracy: 0.5069 - loss: 0.6924 - val_AUC: 0.5082 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 9/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5153 - accuracy: 0.5111 - loss: 0.6923 - val_AUC: 0.5083 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5157 - accuracy: 0.5072 - loss: 0.6922 - val_AUC: 0.5084 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5129 - accuracy: 0.5087 - loss: 0.6923 - val_AUC: 0.5087 - val_accuracy: 0.4976 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5185 - accuracy: 0.5092 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4979 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n",
      "Epoch 13/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5144 - accuracy: 0.5099 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4984 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n",
      "Epoch 14/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5177 - accuracy: 0.5095 - loss: 0.6922 - val_AUC: 0.5085 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "b74dd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vincent": {
   "sessionId": "69652639ec0b92a909c25a12_2025-04-07T12-41-28-233Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
