{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "844b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunthshah/Desktop/Crypto-Price-Moevement-Prediction/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "2575f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_Price</th>\n",
       "      <th>Close_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_10_lag_1</th>\n",
       "      <th>MA_10_lag_2</th>\n",
       "      <th>MA_10_lag_3</th>\n",
       "      <th>MA_10_lag_4</th>\n",
       "      <th>MA_10_lag_5</th>\n",
       "      <th>MA_10_lag_6</th>\n",
       "      <th>MA_10_lag_7</th>\n",
       "      <th>MA_10_lag_8</th>\n",
       "      <th>Momentum_ratios</th>\n",
       "      <th>Sentiment_deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>59097.295565</td>\n",
       "      <td>59029.726208</td>\n",
       "      <td>59900.004347</td>\n",
       "      <td>58784.035582</td>\n",
       "      <td>-67.569357</td>\n",
       "      <td>4462601</td>\n",
       "      <td>49045.482581</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>33.144940</td>\n",
       "      <td>...</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.898218</td>\n",
       "      <td>0.294423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>54973.279224</td>\n",
       "      <td>55151.317602</td>\n",
       "      <td>55396.713428</td>\n",
       "      <td>54378.735255</td>\n",
       "      <td>178.038378</td>\n",
       "      <td>9775141</td>\n",
       "      <td>48852.372428</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>43.650581</td>\n",
       "      <td>...</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934297</td>\n",
       "      <td>-1.048490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>36370.173320</td>\n",
       "      <td>36497.900856</td>\n",
       "      <td>36938.992350</td>\n",
       "      <td>36371.219308</td>\n",
       "      <td>127.727536</td>\n",
       "      <td>5726515</td>\n",
       "      <td>46570.552431</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44.739048</td>\n",
       "      <td>...</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661777</td>\n",
       "      <td>-1.083444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>35454.749016</td>\n",
       "      <td>35059.052567</td>\n",
       "      <td>35211.603012</td>\n",
       "      <td>34107.853810</td>\n",
       "      <td>-395.696449</td>\n",
       "      <td>4617507</td>\n",
       "      <td>43367.089528</td>\n",
       "      <td>43805.992068</td>\n",
       "      <td>37.650721</td>\n",
       "      <td>...</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960577</td>\n",
       "      <td>-1.199126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>35502.135296</td>\n",
       "      <td>35750.062833</td>\n",
       "      <td>36428.171405</td>\n",
       "      <td>35625.323065</td>\n",
       "      <td>247.927537</td>\n",
       "      <td>4181273</td>\n",
       "      <td>44297.612013</td>\n",
       "      <td>43903.552042</td>\n",
       "      <td>39.993981</td>\n",
       "      <td>...</td>\n",
       "      <td>43805.992068</td>\n",
       "      <td>43760.010546</td>\n",
       "      <td>44929.860092</td>\n",
       "      <td>44580.256718</td>\n",
       "      <td>44528.878721</td>\n",
       "      <td>45577.477694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019710</td>\n",
       "      <td>0.543907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open_Price   Close_Price    High_Price     Low_Price  \\\n",
       "0  2023-01-12  59097.295565  59029.726208  59900.004347  58784.035582   \n",
       "1  2023-01-13  54973.279224  55151.317602  55396.713428  54378.735255   \n",
       "2  2023-01-14  36370.173320  36497.900856  36938.992350  36371.219308   \n",
       "3  2023-01-15  35454.749016  35059.052567  35211.603012  34107.853810   \n",
       "4  2023-01-16  35502.135296  35750.062833  36428.171405  35625.323065   \n",
       "\n",
       "   Price_Change   Volume          MA_5         MA_10        RSI  ...  \\\n",
       "0    -67.569357  4462601  49045.482581  44580.256718  33.144940  ...   \n",
       "1    178.038378  9775141  48852.372428  44929.860092  43.650581  ...   \n",
       "2    127.727536  5726515  46570.552431  43760.010546  44.739048  ...   \n",
       "3   -395.696449  4617507  43367.089528  43805.992068  37.650721  ...   \n",
       "4    247.927537  4181273  44297.612013  43903.552042  39.993981  ...   \n",
       "\n",
       "    MA_10_lag_1   MA_10_lag_2   MA_10_lag_3   MA_10_lag_4   MA_10_lag_5  \\\n",
       "0  44528.878721  45577.477694      0.000000      0.000000      0.000000   \n",
       "1  44580.256718  44528.878721  45577.477694      0.000000      0.000000   \n",
       "2  44929.860092  44580.256718  44528.878721  45577.477694      0.000000   \n",
       "3  43760.010546  44929.860092  44580.256718  44528.878721  45577.477694   \n",
       "4  43805.992068  43760.010546  44929.860092  44580.256718  44528.878721   \n",
       "\n",
       "    MA_10_lag_6  MA_10_lag_7  MA_10_lag_8  Momentum_ratios  Sentiment_deltas  \n",
       "0      0.000000          0.0          0.0         1.898218          0.294423  \n",
       "1      0.000000          0.0          0.0         0.934297         -1.048490  \n",
       "2      0.000000          0.0          0.0         0.661777         -1.083444  \n",
       "3      0.000000          0.0          0.0         0.960577         -1.199126  \n",
       "4  45577.477694          0.0          0.0         1.019710          0.543907  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/crypto_price_movement_dataset_with_lags.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "f55a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (34982, 10, 9) (34982,) (7488, 10, 9) (7488,) (7489, 10, 9) (7489,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Split raw DataFrame by time (70/15/15)\n",
    "n = len(df)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = train_end + int(n * 0.15)\n",
    "\n",
    "train_df = df.iloc[:train_end].copy()\n",
    "val_df   = df.iloc[train_end:val_end].copy()\n",
    "test_df  = df.iloc[val_end:].copy()\n",
    "\n",
    "# 2. Identify feature columns (exclude Date, target, and any leakage features)\n",
    "feature_cols = [\n",
    "    'Close_Price','Global_Economy','High_Price','Low_Price',\n",
    "    'MA_10','MA_10_lag_2','Open_Price','RSI','Volatility'\n",
    "    # add any engineered features here\n",
    "]\n",
    "\n",
    "# 3. Fit scaler on TRAIN only, then transform all splits\n",
    "scaler = StandardScaler()\n",
    "train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "val_df[feature_cols]   = scaler.transform(val_df[feature_cols])\n",
    "test_df[feature_cols]  = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "# 4. Function to build time‑windows\n",
    "def create_time_windows(df, feature_cols, window_size=10):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(df)):\n",
    "        X.append(df[feature_cols].iloc[i-window_size:i].values)\n",
    "        y.append(df['Price_Movement'].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 5. Create windowed datasets\n",
    "window_size = 10\n",
    "X_train, y_train = create_time_windows(train_df, feature_cols, window_size)\n",
    "X_val,   y_val   = create_time_windows(val_df,   feature_cols, window_size)\n",
    "X_test,  y_test  = create_time_windows(test_df,  feature_cols, window_size)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      X_train.shape, y_train.shape,\n",
    "      X_val.shape,   y_val.shape,\n",
    "      X_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellUniqueIdByVincent": "5244c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m12,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,053</span> (47.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,053\u001b[0m (47.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,053</span> (47.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,053\u001b[0m (47.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5009 - loss: 0.6959 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6933\n",
      "Epoch 2/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5067 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 3/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5024 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5010 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 5/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5017 - loss: 0.6932 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 6/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5035 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 7/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5013 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6933\n",
      "Epoch 8/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5095 - loss: 0.6927 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6931\n",
      "Epoch 9/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5032 - loss: 0.6931 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6931\n",
      "Epoch 10/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5011 - loss: 0.6932 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6936\n",
      "Epoch 11/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5049 - loss: 0.6929 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6934\n",
      "Epoch 12/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5072 - loss: 0.6927 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6932\n",
      "Epoch 13/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5070 - loss: 0.6926 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6934\n",
      "Epoch 14/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.4961 - loss: 0.6926 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6935\n",
      "Epoch 15/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5021 - loss: 0.6924 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6934\n",
      "Epoch 16/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5052 - loss: 0.6921 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6937\n",
      "Epoch 17/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.4982 - loss: 0.6916 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6934\n",
      "Epoch 18/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5098 - loss: 0.6915 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6940\n",
      "Epoch 19/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5061 - loss: 0.6907 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6950\n",
      "Epoch 20/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - AUC: 0.5000 - accuracy: 0.5049 - loss: 0.6904 - val_AUC: 0.5000 - val_accuracy: 0.4983 - val_loss: 0.6952\n"
     ]
    }
   ],
   "source": [
    "model_simple = Sequential()\n",
    "model_simple.add(LSTM(50, activation='relu', input_shape=(window_size, len(feature_cols))))\n",
    "model_simple.add(Dense(1, activation='sigmoid'))\n",
    "model_simple.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "model_simple.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['AUC', 'accuracy'])\n",
    "print(model_simple.summary())\n",
    "\n",
    "history_simple = model_simple.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "3a2f2"
   },
   "source": [
    "# Attention on top of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "40f97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,944</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ permute_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,944\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │     \u001b[38;5;34m12,416\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │        \u001b[38;5;34m110\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ permute_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,399</span> (126.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,399\u001b[0m (126.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,207</span> (125.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,207\u001b[0m (125.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, BatchNormalization, \n",
    "    Permute, Multiply, Lambda, Softmax, Concatenate\n",
    ")\n",
    "\n",
    "def attention_block(inputs):\n",
    "    # inputs.shape = (batch, timesteps, features)\n",
    "    # 1) Learn a score for each timestep\n",
    "    a = Permute((2,1))(inputs)                       # (batch, features, timesteps)\n",
    "    a = Dense(inputs.shape[1], activation='tanh')(a) # (batch, features, timesteps)\n",
    "    a = Softmax(axis=-1)(a)                          # normalize over timesteps\n",
    "    a_probs = Permute((2,1))(a)                      # (batch, timesteps, features)\n",
    "    # 2) Weight the inputs\n",
    "    output = Multiply()([inputs, a_probs])           # (batch, timesteps, features)\n",
    "    # 3) Sum across time\n",
    "    return Lambda(lambda x: tf.reduce_sum(x, axis=1))(output)\n",
    "\n",
    "def create_lstm_with_attention(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    \n",
    "    x = LSTM(64, return_sequences=True)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention pooling\n",
    "    x = attention_block(x)   # (batch, features)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_attn = create_lstm_with_attention(X_train.shape[1], X_train.shape[2])\n",
    "model_attn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellUniqueIdByVincent": "1cb86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 5s - 8ms/step - AUC: 0.5009 - accuracy: 0.5023 - loss: 0.6932 - val_AUC: 0.4917 - val_accuracy: 0.4959 - val_loss: 0.6934 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5046 - accuracy: 0.5046 - loss: 0.6931 - val_AUC: 0.5033 - val_accuracy: 0.4977 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5002 - accuracy: 0.5015 - loss: 0.6932 - val_AUC: 0.5069 - val_accuracy: 0.4981 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.4945 - accuracy: 0.5028 - loss: 0.6932 - val_AUC: 0.5003 - val_accuracy: 0.4988 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5003 - accuracy: 0.5034 - loss: 0.6931 - val_AUC: 0.5015 - val_accuracy: 0.4979 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5026 - accuracy: 0.5030 - loss: 0.6931 - val_AUC: 0.5020 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.4977 - accuracy: 0.5044 - loss: 0.6932 - val_AUC: 0.4982 - val_accuracy: 0.4931 - val_loss: 0.6932 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5035 - accuracy: 0.5045 - loss: 0.6931 - val_AUC: 0.4885 - val_accuracy: 0.4949 - val_loss: 0.6933 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.4995 - accuracy: 0.5011 - loss: 0.6931 - val_AUC: 0.5047 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5009 - accuracy: 0.5042 - loss: 0.6931 - val_AUC: 0.5005 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.4950 - accuracy: 0.5032 - loss: 0.6931 - val_AUC: 0.4999 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5021 - accuracy: 0.5048 - loss: 0.6931 - val_AUC: 0.5009 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5023 - accuracy: 0.5040 - loss: 0.6931 - val_AUC: 0.5028 - val_accuracy: 0.4983 - val_loss: 0.6932 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5055 - accuracy: 0.5038 - loss: 0.6930 - val_AUC: 0.5061 - val_accuracy: 0.4981 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5052 - accuracy: 0.5037 - loss: 0.6929 - val_AUC: 0.5006 - val_accuracy: 0.4983 - val_loss: 0.6934 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5019 - accuracy: 0.5045 - loss: 0.6930 - val_AUC: 0.5003 - val_accuracy: 0.4983 - val_loss: 0.6933 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5037 - accuracy: 0.5031 - loss: 0.6930 - val_AUC: 0.5050 - val_accuracy: 0.4983 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5066 - accuracy: 0.5044 - loss: 0.6929 - val_AUC: 0.5058 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5077 - accuracy: 0.5045 - loss: 0.6927 - val_AUC: 0.5036 - val_accuracy: 0.5007 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5083 - accuracy: 0.5065 - loss: 0.6929 - val_AUC: 0.5068 - val_accuracy: 0.5019 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5079 - accuracy: 0.5047 - loss: 0.6928 - val_AUC: 0.4990 - val_accuracy: 0.4993 - val_loss: 0.6932 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5089 - accuracy: 0.5084 - loss: 0.6929 - val_AUC: 0.5026 - val_accuracy: 0.5033 - val_loss: 0.6931 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5111 - accuracy: 0.5066 - loss: 0.6928 - val_AUC: 0.5098 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5128 - accuracy: 0.5065 - loss: 0.6926 - val_AUC: 0.5063 - val_accuracy: 0.4984 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5080 - accuracy: 0.5045 - loss: 0.6927 - val_AUC: 0.5050 - val_accuracy: 0.4979 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5122 - accuracy: 0.5071 - loss: 0.6926 - val_AUC: 0.5088 - val_accuracy: 0.5012 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5077 - loss: 0.6926 - val_AUC: 0.5074 - val_accuracy: 0.4964 - val_loss: 0.6930 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5131 - accuracy: 0.5067 - loss: 0.6923 - val_AUC: 0.5098 - val_accuracy: 0.5028 - val_loss: 0.6929 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5155 - accuracy: 0.5089 - loss: 0.6925 - val_AUC: 0.5065 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 6.2500e-05\n",
      "Epoch 30/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5097 - loss: 0.6925 - val_AUC: 0.5072 - val_accuracy: 0.4971 - val_loss: 0.6931 - learning_rate: 6.2500e-05\n",
      "Epoch 31/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5138 - accuracy: 0.5076 - loss: 0.6924 - val_AUC: 0.5059 - val_accuracy: 0.4977 - val_loss: 0.6929 - learning_rate: 6.2500e-05\n",
      "Epoch 32/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5121 - accuracy: 0.5064 - loss: 0.6924 - val_AUC: 0.5063 - val_accuracy: 0.4985 - val_loss: 0.6930 - learning_rate: 6.2500e-05\n",
      "Epoch 33/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5142 - accuracy: 0.5075 - loss: 0.6924 - val_AUC: 0.5055 - val_accuracy: 0.4983 - val_loss: 0.6930 - learning_rate: 6.2500e-05\n",
      "Epoch 34/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5121 - accuracy: 0.5072 - loss: 0.6925 - val_AUC: 0.5066 - val_accuracy: 0.4993 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 35/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5153 - accuracy: 0.5129 - loss: 0.6923 - val_AUC: 0.5040 - val_accuracy: 0.5019 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 36/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5131 - accuracy: 0.5069 - loss: 0.6922 - val_AUC: 0.5046 - val_accuracy: 0.5001 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "75c31"
   },
   "source": [
    "# CNN with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "f3ed7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,345</span> (67.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,345\u001b[0m (67.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,089</span> (66.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,089\u001b[0m (66.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "def create_cnn_lstm(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    \n",
    "    # Convolutional front‑end\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # LSTM back‑end\n",
    "    x = LSTM(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_cnn_lstm = create_cnn_lstm(X_train.shape[1], X_train.shape[2])\n",
    "model_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellUniqueIdByVincent": "28b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 6ms/step - AUC: 0.5104 - accuracy: 0.5056 - loss: 0.6925 - val_AUC: 0.5072 - val_accuracy: 0.5011 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 2/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5106 - accuracy: 0.5051 - loss: 0.6926 - val_AUC: 0.5096 - val_accuracy: 0.5001 - val_loss: 0.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 7ms/step - AUC: 0.5139 - accuracy: 0.5102 - loss: 0.6926 - val_AUC: 0.5098 - val_accuracy: 0.4975 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5148 - accuracy: 0.5083 - loss: 0.6924 - val_AUC: 0.5107 - val_accuracy: 0.4977 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 5/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5104 - accuracy: 0.5067 - loss: 0.6927 - val_AUC: 0.5123 - val_accuracy: 0.4980 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5114 - accuracy: 0.5060 - loss: 0.6925 - val_AUC: 0.5097 - val_accuracy: 0.5000 - val_loss: 0.6929 - learning_rate: 3.1250e-05\n",
      "Epoch 7/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5115 - accuracy: 0.5043 - loss: 0.6924 - val_AUC: 0.5090 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5135 - accuracy: 0.5069 - loss: 0.6925 - val_AUC: 0.5087 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5149 - accuracy: 0.5087 - loss: 0.6924 - val_AUC: 0.5078 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5112 - accuracy: 0.5075 - loss: 0.6925 - val_AUC: 0.5082 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5135 - accuracy: 0.5088 - loss: 0.6924 - val_AUC: 0.5082 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 1.5625e-05\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5136 - accuracy: 0.5087 - loss: 0.6925 - val_AUC: 0.5098 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 13/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5151 - accuracy: 0.5098 - loss: 0.6924 - val_AUC: 0.5087 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 14/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5130 - accuracy: 0.5083 - loss: 0.6923 - val_AUC: 0.5089 - val_accuracy: 0.4993 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 15/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5147 - accuracy: 0.5057 - loss: 0.6925 - val_AUC: 0.5081 - val_accuracy: 0.5001 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 16/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5182 - accuracy: 0.5101 - loss: 0.6923 - val_AUC: 0.5078 - val_accuracy: 0.5003 - val_loss: 0.6929 - learning_rate: 7.8125e-06\n",
      "Epoch 17/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5154 - accuracy: 0.5113 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4995 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 18/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5134 - accuracy: 0.5078 - loss: 0.6924 - val_AUC: 0.5105 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 19/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5158 - accuracy: 0.5109 - loss: 0.6922 - val_AUC: 0.5079 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9a606"
   },
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellUniqueIdByVincent": "fc3b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m88,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,953</span> (351.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,953\u001b[0m (351.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,953</span> (351.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,953\u001b[0m (351.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install keras-tcn if needed: pip install keras-tcn\n",
    "from tcn import TCN\n",
    "\n",
    "def create_tcn(timesteps, n_features):\n",
    "    inp = Input(shape=(timesteps, n_features))\n",
    "    x = TCN(nb_filters=64, kernel_size=3, dilations=[1,2,4,8],\n",
    "            return_sequences=False, activation='relu')(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_tcn = create_tcn(X_train.shape[1], X_train.shape[2])\n",
    "model_tcn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellUniqueIdByVincent": "1476e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 4s - 6ms/step - AUC: 0.5129 - accuracy: 0.5103 - loss: 0.6922 - val_AUC: 0.5074 - val_accuracy: 0.4996 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5166 - accuracy: 0.5111 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4980 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 3/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5144 - accuracy: 0.5081 - loss: 0.6924 - val_AUC: 0.5087 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 - 3s - 6ms/step - AUC: 0.5107 - accuracy: 0.5096 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4983 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 5/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5147 - accuracy: 0.5085 - loss: 0.6925 - val_AUC: 0.5075 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 6/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5161 - accuracy: 0.5080 - loss: 0.6923 - val_AUC: 0.5082 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 3.9063e-06\n",
      "Epoch 7/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5171 - accuracy: 0.5131 - loss: 0.6923 - val_AUC: 0.5091 - val_accuracy: 0.4991 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 8/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5145 - accuracy: 0.5069 - loss: 0.6924 - val_AUC: 0.5082 - val_accuracy: 0.4989 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 9/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5153 - accuracy: 0.5111 - loss: 0.6923 - val_AUC: 0.5083 - val_accuracy: 0.4987 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 10/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5157 - accuracy: 0.5072 - loss: 0.6922 - val_AUC: 0.5084 - val_accuracy: 0.4985 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 11/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5129 - accuracy: 0.5087 - loss: 0.6923 - val_AUC: 0.5087 - val_accuracy: 0.4976 - val_loss: 0.6929 - learning_rate: 1.9531e-06\n",
      "Epoch 12/100\n",
      "547/547 - 3s - 6ms/step - AUC: 0.5185 - accuracy: 0.5092 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4979 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n",
      "Epoch 13/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5144 - accuracy: 0.5099 - loss: 0.6922 - val_AUC: 0.5089 - val_accuracy: 0.4984 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n",
      "Epoch 14/100\n",
      "547/547 - 4s - 7ms/step - AUC: 0.5177 - accuracy: 0.5095 - loss: 0.6922 - val_AUC: 0.5085 - val_accuracy: 0.4988 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellUniqueIdByVincent": "b74dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_LSTM_Attn_TS\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN_LSTM_Attn_TS\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ seq_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ seq_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">328,704</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ permute_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ softmax_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ permute_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_up (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ seq_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ seq_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,792\u001b[0m │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m2,944\u001b[0m │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ spatial_dropout1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │        \u001b[38;5;34m384\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m328,704\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m164,352\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_4 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │        \u001b[38;5;34m110\u001b[0m │ permute_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_2 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_5 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ softmax_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ permute_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ price_up (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,751</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m528,751\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,367</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m528,367\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - AUC: 0.4954 - accuracy: 0.4985 - loss: 1.0179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 79ms/step - AUC: 0.4954 - accuracy: 0.4985 - loss: 1.0178 - val_AUC: 0.5020 - val_accuracy: 0.5016 - val_loss: 0.8565 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5040 - accuracy: 0.5031 - loss: 0.8496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5040 - accuracy: 0.5031 - loss: 0.8496 - val_AUC: 0.4964 - val_accuracy: 0.4963 - val_loss: 0.7925 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5005 - accuracy: 0.4991 - loss: 0.7825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5005 - accuracy: 0.4991 - loss: 0.7825 - val_AUC: 0.4921 - val_accuracy: 0.4944 - val_loss: 0.7465 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5011 - accuracy: 0.5022 - loss: 0.7396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5011 - accuracy: 0.5022 - loss: 0.7396 - val_AUC: 0.5029 - val_accuracy: 0.5048 - val_loss: 0.7182 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5105 - accuracy: 0.5104 - loss: 0.7144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5104 - accuracy: 0.5104 - loss: 0.7144 - val_AUC: 0.5124 - val_accuracy: 0.5110 - val_loss: 0.7056 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5092 - accuracy: 0.5033 - loss: 0.7033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5092 - accuracy: 0.5033 - loss: 0.7033 - val_AUC: 0.5098 - val_accuracy: 0.5096 - val_loss: 0.6991 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.5003 - accuracy: 0.5025 - loss: 0.6994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - AUC: 0.5003 - accuracy: 0.5025 - loss: 0.6994 - val_AUC: 0.5026 - val_accuracy: 0.5035 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5036 - accuracy: 0.5024 - loss: 0.6969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5036 - accuracy: 0.5024 - loss: 0.6969 - val_AUC: 0.4965 - val_accuracy: 0.4976 - val_loss: 0.6978 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.4995 - accuracy: 0.5011 - loss: 0.6969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.4995 - accuracy: 0.5011 - loss: 0.6969 - val_AUC: 0.4964 - val_accuracy: 0.5029 - val_loss: 0.6964 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.4970 - accuracy: 0.5008 - loss: 0.6966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.4970 - accuracy: 0.5008 - loss: 0.6966 - val_AUC: 0.5088 - val_accuracy: 0.4972 - val_loss: 0.6962 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5029 - accuracy: 0.5061 - loss: 0.6969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5029 - accuracy: 0.5061 - loss: 0.6969 - val_AUC: 0.4988 - val_accuracy: 0.5024 - val_loss: 0.6961 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5020 - accuracy: 0.5027 - loss: 0.6961 - val_AUC: 0.4997 - val_accuracy: 0.5056 - val_loss: 0.6961 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.4947 - accuracy: 0.4977 - loss: 0.6965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - AUC: 0.4947 - accuracy: 0.4977 - loss: 0.6965 - val_AUC: 0.5112 - val_accuracy: 0.5021 - val_loss: 0.6956 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.4983 - accuracy: 0.4995 - loss: 0.6959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - AUC: 0.4983 - accuracy: 0.4995 - loss: 0.6959 - val_AUC: 0.5114 - val_accuracy: 0.5035 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5051 - accuracy: 0.5055 - loss: 0.6957 - val_AUC: 0.5071 - val_accuracy: 0.5108 - val_loss: 0.6961 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5150 - accuracy: 0.5128 - loss: 0.6952 - val_AUC: 0.4862 - val_accuracy: 0.4911 - val_loss: 0.6960 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.4999 - accuracy: 0.5023 - loss: 0.6960 - val_AUC: 0.4934 - val_accuracy: 0.4991 - val_loss: 0.6954 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.5027 - accuracy: 0.5029 - loss: 0.6946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5027 - accuracy: 0.5029 - loss: 0.6946 - val_AUC: 0.5078 - val_accuracy: 0.5041 - val_loss: 0.6946 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.4951 - accuracy: 0.5003 - loss: 0.6950 - val_AUC: 0.5095 - val_accuracy: 0.4987 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5012 - accuracy: 0.5055 - loss: 0.6945 - val_AUC: 0.4863 - val_accuracy: 0.4935 - val_loss: 0.6948 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.5140 - accuracy: 0.5135 - loss: 0.6941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5140 - accuracy: 0.5135 - loss: 0.6941 - val_AUC: 0.5068 - val_accuracy: 0.5021 - val_loss: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5099 - accuracy: 0.5072 - loss: 0.6943 - val_AUC: 0.5103 - val_accuracy: 0.5017 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.4973 - accuracy: 0.5010 - loss: 0.6947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.4973 - accuracy: 0.5010 - loss: 0.6947 - val_AUC: 0.5055 - val_accuracy: 0.5004 - val_loss: 0.6940 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.5019 - accuracy: 0.5030 - loss: 0.6941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 87ms/step - AUC: 0.5019 - accuracy: 0.5030 - loss: 0.6941 - val_AUC: 0.5031 - val_accuracy: 0.5056 - val_loss: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5005 - accuracy: 0.5042 - loss: 0.6939 - val_AUC: 0.4958 - val_accuracy: 0.4983 - val_loss: 0.6941 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.5055 - accuracy: 0.5059 - loss: 0.6938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5055 - accuracy: 0.5059 - loss: 0.6938 - val_AUC: 0.5146 - val_accuracy: 0.5146 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.5070 - accuracy: 0.5051 - loss: 0.6938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5070 - accuracy: 0.5051 - loss: 0.6938 - val_AUC: 0.5219 - val_accuracy: 0.5195 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 87ms/step - AUC: 0.5096 - accuracy: 0.5089 - loss: 0.6936 - val_AUC: 0.5068 - val_accuracy: 0.4976 - val_loss: 0.6942 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5162 - accuracy: 0.5116 - loss: 0.6937 - val_AUC: 0.4990 - val_accuracy: 0.4908 - val_loss: 0.6939 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - AUC: 0.5144 - accuracy: 0.5123 - loss: 0.6933 - val_AUC: 0.5109 - val_accuracy: 0.5043 - val_loss: 0.6939 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 85ms/step - AUC: 0.5139 - accuracy: 0.5166 - loss: 0.6935 - val_AUC: 0.5088 - val_accuracy: 0.5104 - val_loss: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5176 - accuracy: 0.5110 - loss: 0.6933 - val_AUC: 0.5015 - val_accuracy: 0.5008 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5276 - accuracy: 0.5223 - loss: 0.6927 - val_AUC: 0.5142 - val_accuracy: 0.5108 - val_loss: 0.6939 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - AUC: 0.5308 - accuracy: 0.5273 - loss: 0.6921 - val_AUC: 0.5107 - val_accuracy: 0.5055 - val_loss: 0.6946 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 83ms/step - AUC: 0.5349 - accuracy: 0.5259 - loss: 0.6919 - val_AUC: 0.5106 - val_accuracy: 0.5031 - val_loss: 0.6961 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - AUC: 0.5450 - accuracy: 0.5316 - loss: 0.6906 - val_AUC: 0.5082 - val_accuracy: 0.5100 - val_loss: 0.6960 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - AUC: 0.5461 - accuracy: 0.5344 - loss: 0.6905 - val_AUC: 0.5052 - val_accuracy: 0.5085 - val_loss: 0.6958 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, SpatialDropout1D, LayerNormalization,\n",
    "    Bidirectional, LSTM, Dense, Dropout, BatchNormalization,\n",
    "    Permute, Multiply, Softmax, Lambda, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# --- 1) Attention Block ---\n",
    "def attention_block(inputs):\n",
    "    # inputs.shape = (batch, timesteps, features)\n",
    "    # 1) Score each timestep\n",
    "    a = Permute((2,1))(inputs)                          # (batch, features, timesteps)\n",
    "    a = Dense(inputs.shape[1], activation='tanh')(a)    # learnable scoring\n",
    "    a = Softmax(axis=-1)(a)                             # normalize over timesteps\n",
    "    a = Permute((2,1))(a)                               # back to (batch, timesteps, features)\n",
    "    # 2) Weight inputs and sum\n",
    "    weighted = Multiply()([inputs, a])\n",
    "    return Lambda(lambda x: tf.reduce_sum(x, axis=1))(weighted)\n",
    "\n",
    "# --- 2) Build the Hybrid CNN→Bi‑LSTM→Attention Model ---\n",
    "def build_robust_ts_model(window_size, n_features):\n",
    "    seq_in = Input(shape=(window_size, n_features), name='seq_input')\n",
    "    \n",
    "    # 2A) Spatial Dropout for regularizing across features\n",
    "    x = SpatialDropout1D(0.2)(seq_in)\n",
    "    \n",
    "    # 2B) Parallel CNN “motif” towers\n",
    "    t1 = Conv1D(64, 3, padding='same', activation='relu')(x)\n",
    "    t2 = Conv1D(64, 5, padding='same', activation='relu')(x)\n",
    "    t3 = Conv1D(64, 7, padding='same', activation='relu')(x)\n",
    "    x = Concatenate()([t1, t2, t3])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # 2C) Stacked Bidirectional LSTMs with LayerNorm + Dropout\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # 2D) Attention pooling over time\n",
    "    x = attention_block(x)   # → shape (batch, features)\n",
    "    \n",
    "    # 2E) Deep Dense Head with regularization\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # 2F) Final binary output\n",
    "    out = Dense(1, activation='sigmoid', name='price_up')(x)\n",
    "    \n",
    "    model = Model(seq_in, out, name='CNN_LSTM_Attn_TS')\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# --- 3) Instantiate & Train ---\n",
    "# assuming you have your windowed data X_train, y_train, X_val, y_val:\n",
    "window_size, n_features = X_train.shape[1], X_train.shape[2]\n",
    "model = build_robust_ts_model(window_size, n_features)\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_ts_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellUniqueIdByVincent": "1e82d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "Confusion Matrix:\n",
      "[[1346 2411]\n",
      " [1187 2544]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.36      0.43      3757\n",
      "           1       0.51      0.68      0.59      3731\n",
      "\n",
      "    accuracy                           0.52      7488\n",
      "   macro avg       0.52      0.52      0.51      7488\n",
      "weighted avg       0.52      0.52      0.51      7488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = (model.predict(X_val) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "0adc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.7972 - val_loss: 0.7263\n",
      "Epoch 2/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.7074 - val_loss: 0.6994\n",
      "Epoch 3/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6833 - val_loss: 0.6808\n",
      "Epoch 4/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6672 - val_loss: 0.6665\n",
      "Epoch 5/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6542 - val_loss: 0.6550\n",
      "Epoch 6/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6431 - val_loss: 0.6442\n",
      "Epoch 7/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6336 - val_loss: 0.6353\n",
      "Epoch 8/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6266 - val_loss: 0.6312\n",
      "Epoch 9/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6194 - val_loss: 0.6252\n",
      "Epoch 10/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6147 - val_loss: 0.6202\n",
      "Epoch 11/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6091 - val_loss: 0.6158\n",
      "Epoch 12/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.6036 - val_loss: 0.6104\n",
      "Epoch 13/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6008 - val_loss: 0.6055\n",
      "Epoch 14/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.5972 - val_loss: 0.6033\n",
      "Epoch 15/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.5944 - val_loss: 0.6007\n",
      "Epoch 16/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.5888 - val_loss: 0.5955\n",
      "Epoch 17/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.5848 - val_loss: 0.5909\n",
      "Epoch 18/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.5824 - val_loss: 0.5889\n",
      "Epoch 19/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5793 - val_loss: 0.5851\n",
      "Epoch 20/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.5766 - val_loss: 0.5832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x357cb3c70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, RepeatVector, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# === 1) Derive magnitude labels from Price_Change ===\n",
    "# Note: train_df, val_df, test_df still contain 'Price_Change'\n",
    "y_train_mag = train_df['Price_Change'].iloc[window_size:].values\n",
    "y_val_mag   = val_df['Price_Change'].iloc[window_size:].values\n",
    "y_test_mag  = test_df['Price_Change'].iloc[window_size:].values\n",
    "\n",
    "# === 2) Self‑Supervised Pretraining: Sequence Autoencoder ===\n",
    "ae_in = Input(shape=(window_size, len(feature_cols)))\n",
    "# Encoder\n",
    "encoded = LSTM(128, return_sequences=False)(ae_in)\n",
    "# Decoder\n",
    "decoded = RepeatVector(window_size)(encoded)\n",
    "decoded = LSTM(len(feature_cols), return_sequences=True)(decoded)\n",
    "\n",
    "autoencoder = Model(ae_in, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    validation_data=(X_val, X_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "87246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - direction_AUC: 0.4959 - direction_loss: 0.8468 - loss: 41366.0820 - magnitude_loss: 82729.7656 - val_direction_AUC: 0.4961 - val_direction_loss: 0.7006 - val_loss: 42822.0391 - val_magnitude_loss: 85641.9375\n",
      "Epoch 2/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.4989 - direction_loss: 0.7034 - loss: 41617.4102 - magnitude_loss: 83232.6562 - val_direction_AUC: 0.4976 - val_direction_loss: 0.6956 - val_loss: 42834.5430 - val_magnitude_loss: 85666.9297\n",
      "Epoch 3/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5028 - direction_loss: 0.6958 - loss: 41418.0625 - magnitude_loss: 82833.9219 - val_direction_AUC: 0.4999 - val_direction_loss: 0.6943 - val_loss: 42854.2734 - val_magnitude_loss: 85706.3516\n",
      "Epoch 4/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5012 - direction_loss: 0.6956 - loss: 41574.9648 - magnitude_loss: 83147.7422 - val_direction_AUC: 0.4932 - val_direction_loss: 0.6977 - val_loss: 42868.5156 - val_magnitude_loss: 85734.7656\n",
      "Epoch 5/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5009 - direction_loss: 0.6955 - loss: 41645.1289 - magnitude_loss: 83287.9844 - val_direction_AUC: 0.4940 - val_direction_loss: 0.6949 - val_loss: 42887.6719 - val_magnitude_loss: 85773.0156\n",
      "Epoch 6/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.5015 - direction_loss: 0.6957 - loss: 41638.7734 - magnitude_loss: 83275.2344 - val_direction_AUC: 0.5142 - val_direction_loss: 0.6939 - val_loss: 42931.2227 - val_magnitude_loss: 85860.0312\n",
      "Epoch 7/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5237 - direction_loss: 0.6934 - loss: 41257.6094 - magnitude_loss: 82512.7734 - val_direction_AUC: 0.5000 - val_direction_loss: 0.6976 - val_loss: 43056.8438 - val_magnitude_loss: 86111.1797\n",
      "Epoch 8/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5418 - direction_loss: 0.6914 - loss: 40864.0117 - magnitude_loss: 81725.4844 - val_direction_AUC: 0.5018 - val_direction_loss: 0.6945 - val_loss: 43277.6172 - val_magnitude_loss: 86552.5547\n",
      "Epoch 9/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5567 - direction_loss: 0.6896 - loss: 40378.2031 - magnitude_loss: 80753.6719 - val_direction_AUC: 0.4922 - val_direction_loss: 0.6967 - val_loss: 43535.1016 - val_magnitude_loss: 87067.4141\n",
      "Epoch 10/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.5861 - direction_loss: 0.6824 - loss: 39913.2383 - magnitude_loss: 79823.6953 - val_direction_AUC: 0.4895 - val_direction_loss: 0.7021 - val_loss: 44205.4883 - val_magnitude_loss: 88408.0078\n",
      "Epoch 11/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.6146 - direction_loss: 0.6722 - loss: 38786.2227 - magnitude_loss: 77569.5234 - val_direction_AUC: 0.4889 - val_direction_loss: 0.7214 - val_loss: 44869.7734 - val_magnitude_loss: 89736.3750\n",
      "Epoch 12/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.6417 - direction_loss: 0.6608 - loss: 37991.7578 - magnitude_loss: 75980.4844 - val_direction_AUC: 0.4835 - val_direction_loss: 0.7349 - val_loss: 46073.2109 - val_magnitude_loss: 92143.1484\n",
      "Epoch 13/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.6770 - direction_loss: 0.6429 - loss: 36252.3047 - magnitude_loss: 72501.4453 - val_direction_AUC: 0.4936 - val_direction_loss: 0.7269 - val_loss: 47106.1797 - val_magnitude_loss: 94208.8828\n",
      "Epoch 14/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.7020 - direction_loss: 0.6264 - loss: 34422.5234 - magnitude_loss: 68841.7812 - val_direction_AUC: 0.4854 - val_direction_loss: 0.7478 - val_loss: 49963.4297 - val_magnitude_loss: 99923.2812\n",
      "Epoch 15/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.7277 - direction_loss: 0.6101 - loss: 33040.0742 - magnitude_loss: 66076.8047 - val_direction_AUC: 0.4918 - val_direction_loss: 0.7627 - val_loss: 49842.5195 - val_magnitude_loss: 99681.2500\n",
      "Epoch 16/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.7564 - direction_loss: 0.5852 - loss: 30253.9824 - magnitude_loss: 60504.5938 - val_direction_AUC: 0.4877 - val_direction_loss: 0.8708 - val_loss: 51626.2109 - val_magnitude_loss: 103248.3516\n",
      "Epoch 17/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.7775 - direction_loss: 0.5647 - loss: 28820.3652 - magnitude_loss: 57637.2617 - val_direction_AUC: 0.4973 - val_direction_loss: 0.8592 - val_loss: 53645.5391 - val_magnitude_loss: 107286.9375\n",
      "Epoch 18/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8033 - direction_loss: 0.5388 - loss: 26815.1191 - magnitude_loss: 53626.6758 - val_direction_AUC: 0.4977 - val_direction_loss: 0.8817 - val_loss: 55175.0859 - val_magnitude_loss: 110345.8203\n",
      "Epoch 19/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8229 - direction_loss: 0.5163 - loss: 24929.4375 - magnitude_loss: 49855.2773 - val_direction_AUC: 0.4967 - val_direction_loss: 0.8584 - val_loss: 56884.7539 - val_magnitude_loss: 113765.1641\n",
      "Epoch 20/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8443 - direction_loss: 0.4894 - loss: 23297.1875 - magnitude_loss: 46590.6875 - val_direction_AUC: 0.4926 - val_direction_loss: 0.9793 - val_loss: 58505.5820 - val_magnitude_loss: 117006.4844\n",
      "Epoch 21/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8581 - direction_loss: 0.4688 - loss: 21547.6172 - magnitude_loss: 43091.5117 - val_direction_AUC: 0.4929 - val_direction_loss: 0.9799 - val_loss: 59345.4531 - val_magnitude_loss: 118686.1406\n",
      "Epoch 22/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - direction_AUC: 0.8735 - direction_loss: 0.4460 - loss: 20056.4395 - magnitude_loss: 40109.1484 - val_direction_AUC: 0.4987 - val_direction_loss: 1.0375 - val_loss: 61655.3281 - val_magnitude_loss: 123305.6719\n",
      "Epoch 23/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8837 - direction_loss: 0.4294 - loss: 18494.8867 - magnitude_loss: 36986.0234 - val_direction_AUC: 0.4978 - val_direction_loss: 1.1218 - val_loss: 61676.4961 - val_magnitude_loss: 123347.7578\n",
      "Epoch 24/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.8952 - direction_loss: 0.4089 - loss: 17253.5801 - magnitude_loss: 34503.3594 - val_direction_AUC: 0.4957 - val_direction_loss: 1.1235 - val_loss: 65774.6641 - val_magnitude_loss: 131544.0156\n",
      "Epoch 25/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.9052 - direction_loss: 0.3906 - loss: 15995.8262 - magnitude_loss: 31987.8223 - val_direction_AUC: 0.4979 - val_direction_loss: 1.2207 - val_loss: 63481.0859 - val_magnitude_loss: 126956.5469\n",
      "Epoch 26/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.9148 - direction_loss: 0.3716 - loss: 14820.4434 - magnitude_loss: 29636.9707 - val_direction_AUC: 0.4979 - val_direction_loss: 1.3017 - val_loss: 65774.4844 - val_magnitude_loss: 131543.1250\n",
      "Epoch 27/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - direction_AUC: 0.9203 - direction_loss: 0.3598 - loss: 14015.2129 - magnitude_loss: 28026.4941 - val_direction_AUC: 0.4972 - val_direction_loss: 1.1235 - val_loss: 65399.6289 - val_magnitude_loss: 130793.7188\n",
      "Epoch 28/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9274 - direction_loss: 0.3433 - loss: 12924.4414 - magnitude_loss: 25844.8691 - val_direction_AUC: 0.4972 - val_direction_loss: 1.2457 - val_loss: 67353.5000 - val_magnitude_loss: 134701.2188\n",
      "Epoch 29/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9326 - direction_loss: 0.3316 - loss: 12312.1328 - magnitude_loss: 24620.2383 - val_direction_AUC: 0.4941 - val_direction_loss: 1.1792 - val_loss: 67841.6719 - val_magnitude_loss: 135677.5781\n",
      "Epoch 30/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9405 - direction_loss: 0.3114 - loss: 11561.0908 - magnitude_loss: 23118.1504 - val_direction_AUC: 0.4963 - val_direction_loss: 1.2739 - val_loss: 67835.6016 - val_magnitude_loss: 135665.1562\n",
      "Epoch 31/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9433 - direction_loss: 0.3049 - loss: 10802.7207 - magnitude_loss: 21601.3242 - val_direction_AUC: 0.4976 - val_direction_loss: 1.2836 - val_loss: 69093.3516 - val_magnitude_loss: 138180.5469\n",
      "Epoch 32/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9492 - direction_loss: 0.2883 - loss: 10094.6260 - magnitude_loss: 20185.1152 - val_direction_AUC: 0.4955 - val_direction_loss: 1.3243 - val_loss: 69915.6953 - val_magnitude_loss: 139825.1250\n",
      "Epoch 33/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9520 - direction_loss: 0.2804 - loss: 9738.0967 - magnitude_loss: 19472.0195 - val_direction_AUC: 0.4961 - val_direction_loss: 1.5113 - val_loss: 70534.9922 - val_magnitude_loss: 141063.2812\n",
      "Epoch 34/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9531 - direction_loss: 0.2774 - loss: 9390.1523 - magnitude_loss: 18776.0605 - val_direction_AUC: 0.4961 - val_direction_loss: 1.5244 - val_loss: 70482.9688 - val_magnitude_loss: 140959.1250\n",
      "Epoch 35/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9600 - direction_loss: 0.2560 - loss: 8487.1611 - magnitude_loss: 16970.0078 - val_direction_AUC: 0.4939 - val_direction_loss: 1.5354 - val_loss: 71582.9844 - val_magnitude_loss: 143159.0781\n",
      "Epoch 36/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9615 - direction_loss: 0.2519 - loss: 8343.1797 - magnitude_loss: 16682.0254 - val_direction_AUC: 0.4955 - val_direction_loss: 1.4394 - val_loss: 71050.0391 - val_magnitude_loss: 142093.2969\n",
      "Epoch 37/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9620 - direction_loss: 0.2505 - loss: 8062.3550 - magnitude_loss: 16120.3174 - val_direction_AUC: 0.4962 - val_direction_loss: 1.5529 - val_loss: 71823.4375 - val_magnitude_loss: 143639.7812\n",
      "Epoch 38/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9658 - direction_loss: 0.2370 - loss: 7677.9292 - magnitude_loss: 15351.4209 - val_direction_AUC: 0.4917 - val_direction_loss: 1.3208 - val_loss: 72456.1875 - val_magnitude_loss: 144905.7031\n",
      "Epoch 39/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9664 - direction_loss: 0.2353 - loss: 7205.8330 - magnitude_loss: 14407.1963 - val_direction_AUC: 0.4940 - val_direction_loss: 1.4931 - val_loss: 71891.9766 - val_magnitude_loss: 143776.8281\n",
      "Epoch 40/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9693 - direction_loss: 0.2252 - loss: 6999.1416 - magnitude_loss: 13993.7256 - val_direction_AUC: 0.4951 - val_direction_loss: 1.5531 - val_loss: 71557.4219 - val_magnitude_loss: 143107.6250\n",
      "Epoch 41/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9700 - direction_loss: 0.2221 - loss: 6888.1035 - magnitude_loss: 13771.5889 - val_direction_AUC: 0.4966 - val_direction_loss: 1.6688 - val_loss: 72286.6250 - val_magnitude_loss: 144565.6875\n",
      "Epoch 42/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9698 - direction_loss: 0.2236 - loss: 6693.6558 - magnitude_loss: 13382.6279 - val_direction_AUC: 0.4959 - val_direction_loss: 1.6353 - val_loss: 72387.0156 - val_magnitude_loss: 144766.4375\n",
      "Epoch 43/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9717 - direction_loss: 0.2156 - loss: 6363.2080 - magnitude_loss: 12721.6758 - val_direction_AUC: 0.4931 - val_direction_loss: 1.5997 - val_loss: 73719.8750 - val_magnitude_loss: 147432.1719\n",
      "Epoch 44/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9721 - direction_loss: 0.2150 - loss: 6163.6733 - magnitude_loss: 12322.5527 - val_direction_AUC: 0.4964 - val_direction_loss: 1.7869 - val_loss: 72957.4141 - val_magnitude_loss: 145906.7812\n",
      "Epoch 45/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9741 - direction_loss: 0.2069 - loss: 5960.8828 - magnitude_loss: 11916.9209 - val_direction_AUC: 0.4965 - val_direction_loss: 1.7572 - val_loss: 74759.0312 - val_magnitude_loss: 149510.0781\n",
      "Epoch 46/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9747 - direction_loss: 0.2047 - loss: 5981.8618 - magnitude_loss: 11958.8105 - val_direction_AUC: 0.4953 - val_direction_loss: 1.8379 - val_loss: 73730.7422 - val_magnitude_loss: 147453.2500\n",
      "Epoch 47/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9740 - direction_loss: 0.2073 - loss: 5699.2373 - magnitude_loss: 11393.5449 - val_direction_AUC: 0.4971 - val_direction_loss: 1.6410 - val_loss: 73420.1797 - val_magnitude_loss: 146832.4844\n",
      "Epoch 48/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - direction_AUC: 0.9756 - direction_loss: 0.2011 - loss: 5598.1519 - magnitude_loss: 11191.2832 - val_direction_AUC: 0.4951 - val_direction_loss: 1.9853 - val_loss: 73243.8438 - val_magnitude_loss: 146479.0312\n",
      "Epoch 49/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9752 - direction_loss: 0.2028 - loss: 5519.6445 - magnitude_loss: 11034.1855 - val_direction_AUC: 0.4975 - val_direction_loss: 1.7616 - val_loss: 73819.6094 - val_magnitude_loss: 147630.9062\n",
      "Epoch 50/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - direction_AUC: 0.9760 - direction_loss: 0.1990 - loss: 5355.5879 - magnitude_loss: 10706.0234 - val_direction_AUC: 0.4981 - val_direction_loss: 1.6244 - val_loss: 72813.9141 - val_magnitude_loss: 145619.7188\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      "[[1788 1981]\n",
      " [1821 1899]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48      3769\n",
      "           1       0.49      0.51      0.50      3720\n",
      "\n",
      "    accuracy                           0.49      7489\n",
      "   macro avg       0.49      0.49      0.49      7489\n",
      "weighted avg       0.49      0.49      0.49      7489\n",
      "\n",
      "\n",
      "Test AUC: 0.4880\n"
     ]
    }
   ],
   "source": [
    "# Extract the encoder\n",
    "encoder = Model(ae_in, encoded)\n",
    "# Optionally freeze encoder weights:\n",
    "# encoder.trainable = False\n",
    "\n",
    "# === 3) Build Multi‑Task Classifier Using Pretrained Encoder ===\n",
    "seq_in = Input(shape=(window_size, len(feature_cols)))\n",
    "x = encoder(seq_in)\n",
    "\n",
    "# Dense head\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(1e-3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Outputs\n",
    "dir_out = Dense(1, activation='sigmoid', name='direction')(x)\n",
    "mag_out = Dense(1, activation='linear',  name='magnitude')(x)\n",
    "\n",
    "model = Model(seq_in, [dir_out, mag_out])\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss={'direction':'binary_crossentropy','magnitude':'mse'},\n",
    "    loss_weights={'direction':1.0,'magnitude':0.5},\n",
    "    metrics={'direction':'AUC'}\n",
    ")\n",
    "\n",
    "# === 4) Train Classifier ===\n",
    "model.fit(\n",
    "    X_train, {'direction': y_train, 'magnitude': y_train_mag},\n",
    "    validation_data=(X_val, {'direction': y_val, 'magnitude': y_val_mag}),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellUniqueIdByVincent": "64cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      "[[1788 1981]\n",
      " [1821 1899]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48      3769\n",
      "           1       0.49      0.51      0.50      3720\n",
      "\n",
      "    accuracy                           0.49      7489\n",
      "   macro avg       0.49      0.49      0.49      7489\n",
      "weighted avg       0.49      0.49      0.49      7489\n",
      "\n",
      "\n",
      "Test AUC: 0.4880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 5) Evaluate on Test Set ===\n",
    "dir_pred_prob, mag_pred = model.predict(X_test)\n",
    "dir_pred = (dir_pred_prob.flatten() > 0.5).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, dir_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, dir_pred))\n",
    "\n",
    "print(f\"\\nTest AUC: {roc_auc_score(y_test, dir_pred_prob):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellUniqueIdByVincent": "20c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 49ms/step - AUC: 0.4962 - accuracy: 0.4988 - loss: 0.8007 - val_AUC: 0.5044 - val_accuracy: 0.4987 - val_loss: 0.6956\n",
      "Epoch 2/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - AUC: 0.4982 - accuracy: 0.4994 - loss: 0.7072 - val_AUC: 0.5058 - val_accuracy: 0.5043 - val_loss: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - AUC: 0.5004 - accuracy: 0.4983 - loss: 0.6964 - val_AUC: 0.5109 - val_accuracy: 0.5071 - val_loss: 0.6932\n",
      "Epoch 4/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - AUC: 0.4954 - accuracy: 0.5025 - loss: 0.6948 - val_AUC: 0.4993 - val_accuracy: 0.4933 - val_loss: 0.6938\n",
      "Epoch 5/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - AUC: 0.5065 - accuracy: 0.5027 - loss: 0.6938 - val_AUC: 0.5095 - val_accuracy: 0.5084 - val_loss: 0.6932\n",
      "Epoch 6/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 56ms/step - AUC: 0.4982 - accuracy: 0.4988 - loss: 0.6942 - val_AUC: 0.5126 - val_accuracy: 0.5031 - val_loss: 0.6930\n",
      "Epoch 7/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 54ms/step - AUC: 0.5051 - accuracy: 0.5083 - loss: 0.6937 - val_AUC: 0.5059 - val_accuracy: 0.5110 - val_loss: 0.6933\n",
      "Epoch 8/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - AUC: 0.5002 - accuracy: 0.5014 - loss: 0.6940 - val_AUC: 0.5037 - val_accuracy: 0.4983 - val_loss: 0.6936\n",
      "Epoch 9/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - AUC: 0.5043 - accuracy: 0.5034 - loss: 0.6937 - val_AUC: 0.5029 - val_accuracy: 0.5053 - val_loss: 0.6938\n",
      "Epoch 10/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - AUC: 0.4999 - accuracy: 0.5004 - loss: 0.6941 - val_AUC: 0.4979 - val_accuracy: 0.5011 - val_loss: 0.6935\n",
      "Epoch 11/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - AUC: 0.5097 - accuracy: 0.5106 - loss: 0.6932 - val_AUC: 0.4994 - val_accuracy: 0.5005 - val_loss: 0.6934\n",
      "Epoch 12/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5044 - accuracy: 0.5041 - loss: 0.6938 - val_AUC: 0.4906 - val_accuracy: 0.4952 - val_loss: 0.6939\n",
      "Epoch 13/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5074 - accuracy: 0.5060 - loss: 0.6937 - val_AUC: 0.5061 - val_accuracy: 0.5012 - val_loss: 0.6936\n",
      "Epoch 14/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - AUC: 0.5023 - accuracy: 0.5031 - loss: 0.6937 - val_AUC: 0.4928 - val_accuracy: 0.4992 - val_loss: 0.6935\n",
      "Epoch 15/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5099 - accuracy: 0.5072 - loss: 0.6933 - val_AUC: 0.4843 - val_accuracy: 0.4912 - val_loss: 0.6941\n",
      "Epoch 16/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - AUC: 0.5072 - accuracy: 0.5061 - loss: 0.6937 - val_AUC: 0.5047 - val_accuracy: 0.4992 - val_loss: 0.6940\n",
      "Epoch 17/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5032 - accuracy: 0.5057 - loss: 0.6939 - val_AUC: 0.4884 - val_accuracy: 0.4940 - val_loss: 0.6945\n",
      "Epoch 18/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - AUC: 0.4938 - accuracy: 0.4942 - loss: 0.6940 - val_AUC: 0.4955 - val_accuracy: 0.4955 - val_loss: 0.6934\n",
      "Epoch 19/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.4964 - accuracy: 0.5007 - loss: 0.6938 - val_AUC: 0.4853 - val_accuracy: 0.4964 - val_loss: 0.6936\n",
      "Epoch 20/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.4998 - accuracy: 0.4987 - loss: 0.6935 - val_AUC: 0.5044 - val_accuracy: 0.5011 - val_loss: 0.6932\n",
      "Epoch 21/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - AUC: 0.5059 - accuracy: 0.5021 - loss: 0.6935 - val_AUC: 0.4988 - val_accuracy: 0.4995 - val_loss: 0.6954\n",
      "Epoch 22/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - AUC: 0.5067 - accuracy: 0.5080 - loss: 0.6936 - val_AUC: 0.5110 - val_accuracy: 0.4987 - val_loss: 0.6936\n",
      "Epoch 23/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5026 - accuracy: 0.5051 - loss: 0.6937 - val_AUC: 0.5084 - val_accuracy: 0.5001 - val_loss: 0.6933\n",
      "Epoch 24/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - AUC: 0.4963 - accuracy: 0.4976 - loss: 0.6938 - val_AUC: 0.4960 - val_accuracy: 0.4955 - val_loss: 0.6944\n",
      "Epoch 25/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5012 - accuracy: 0.5015 - loss: 0.6937 - val_AUC: 0.5048 - val_accuracy: 0.4983 - val_loss: 0.6936\n",
      "Epoch 26/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5007 - accuracy: 0.5032 - loss: 0.6934 - val_AUC: 0.4986 - val_accuracy: 0.4956 - val_loss: 0.6935\n",
      "Epoch 27/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - AUC: 0.5009 - accuracy: 0.5008 - loss: 0.6933 - val_AUC: 0.5089 - val_accuracy: 0.5104 - val_loss: 0.6931\n",
      "Epoch 28/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5114 - accuracy: 0.5086 - loss: 0.6931 - val_AUC: 0.5043 - val_accuracy: 0.5044 - val_loss: 0.6937\n",
      "Epoch 29/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - AUC: 0.5078 - accuracy: 0.5059 - loss: 0.6932 - val_AUC: 0.5031 - val_accuracy: 0.5055 - val_loss: 0.6933\n",
      "Epoch 30/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5072 - accuracy: 0.5049 - loss: 0.6932 - val_AUC: 0.4967 - val_accuracy: 0.4919 - val_loss: 0.6933\n",
      "Epoch 31/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5175 - accuracy: 0.5116 - loss: 0.6928 - val_AUC: 0.5116 - val_accuracy: 0.5130 - val_loss: 0.6932\n",
      "Epoch 32/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - AUC: 0.5069 - accuracy: 0.5031 - loss: 0.6931 - val_AUC: 0.5011 - val_accuracy: 0.4968 - val_loss: 0.6936\n",
      "Epoch 33/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - AUC: 0.5036 - accuracy: 0.5006 - loss: 0.6933 - val_AUC: 0.5071 - val_accuracy: 0.5024 - val_loss: 0.6934\n",
      "Epoch 34/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5190 - accuracy: 0.5132 - loss: 0.6924 - val_AUC: 0.5059 - val_accuracy: 0.5039 - val_loss: 0.6936\n",
      "Epoch 35/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5158 - accuracy: 0.5110 - loss: 0.6927 - val_AUC: 0.5034 - val_accuracy: 0.5019 - val_loss: 0.6935\n",
      "Epoch 36/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5134 - accuracy: 0.5059 - loss: 0.6927 - val_AUC: 0.4915 - val_accuracy: 0.4939 - val_loss: 0.6942\n",
      "Epoch 37/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5164 - accuracy: 0.5098 - loss: 0.6927 - val_AUC: 0.5008 - val_accuracy: 0.4931 - val_loss: 0.6944\n",
      "Epoch 38/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5252 - accuracy: 0.5185 - loss: 0.6920 - val_AUC: 0.5020 - val_accuracy: 0.5072 - val_loss: 0.6946\n",
      "Epoch 39/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 50ms/step - AUC: 0.5331 - accuracy: 0.5214 - loss: 0.6913 - val_AUC: 0.5070 - val_accuracy: 0.5016 - val_loss: 0.6934\n",
      "Epoch 40/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - AUC: 0.5324 - accuracy: 0.5228 - loss: 0.6911 - val_AUC: 0.4966 - val_accuracy: 0.4971 - val_loss: 0.6945\n",
      "Epoch 41/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5416 - accuracy: 0.5299 - loss: 0.6901 - val_AUC: 0.4992 - val_accuracy: 0.4961 - val_loss: 0.6956\n",
      "Epoch 42/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5383 - accuracy: 0.5249 - loss: 0.6904 - val_AUC: 0.4971 - val_accuracy: 0.4984 - val_loss: 0.6952\n",
      "Epoch 43/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5469 - accuracy: 0.5331 - loss: 0.6894 - val_AUC: 0.5079 - val_accuracy: 0.5055 - val_loss: 0.6950\n",
      "Epoch 44/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5559 - accuracy: 0.5368 - loss: 0.6880 - val_AUC: 0.5022 - val_accuracy: 0.5039 - val_loss: 0.6964\n",
      "Epoch 45/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - AUC: 0.5531 - accuracy: 0.5375 - loss: 0.6882 - val_AUC: 0.4975 - val_accuracy: 0.4976 - val_loss: 0.6990\n",
      "Epoch 46/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - AUC: 0.5643 - accuracy: 0.5467 - loss: 0.6869 - val_AUC: 0.4945 - val_accuracy: 0.4993 - val_loss: 0.7015\n",
      "Epoch 47/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - AUC: 0.5628 - accuracy: 0.5431 - loss: 0.6866 - val_AUC: 0.4986 - val_accuracy: 0.5011 - val_loss: 0.7018\n",
      "Epoch 48/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - AUC: 0.5706 - accuracy: 0.5492 - loss: 0.6850 - val_AUC: 0.4963 - val_accuracy: 0.4981 - val_loss: 0.7005\n",
      "Epoch 49/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - AUC: 0.5704 - accuracy: 0.5485 - loss: 0.6846 - val_AUC: 0.5019 - val_accuracy: 0.4971 - val_loss: 0.7046\n",
      "Epoch 50/50\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - AUC: 0.5812 - accuracy: 0.5558 - loss: 0.6823 - val_AUC: 0.4961 - val_accuracy: 0.4996 - val_loss: 0.7068\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Confusion Matrix:\n",
      "[[1487 2282]\n",
      " [1445 2275]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.39      0.44      3769\n",
      "           1       0.50      0.61      0.55      3720\n",
      "\n",
      "    accuracy                           0.50      7489\n",
      "   macro avg       0.50      0.50      0.50      7489\n",
      "weighted avg       0.50      0.50      0.50      7489\n",
      "\n",
      "\n",
      "Test AUC: 0.5058\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, SpatialDropout1D, LayerNormalization,\n",
    "    Bidirectional, LSTM, Dense, Dropout, BatchNormalization,\n",
    "    Permute, Multiply, Softmax, Lambda, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Attention block\n",
    "def attention_block(inputs):\n",
    "    a = Permute((2,1))(inputs)\n",
    "    a = Dense(inputs.shape[1], activation='tanh')(a)\n",
    "    a = Softmax(axis=-1)(a)\n",
    "    a = Permute((2,1))(a)\n",
    "    weighted = Multiply()([inputs, a])\n",
    "    return Lambda(lambda x: tf.reduce_sum(x, axis=1))(weighted)\n",
    "\n",
    "def build_final_model(window_size, n_features):\n",
    "    seq_in = Input(shape=(window_size, n_features))\n",
    "    x = SpatialDropout1D(0.2)(seq_in)\n",
    "\n",
    "    # CNN motif towers\n",
    "    t1 = Conv1D(64, 3, padding='same', activation='relu')(x)\n",
    "    t2 = Conv1D(64, 5, padding='same', activation='relu')(x)\n",
    "    t3 = Conv1D(64, 7, padding='same', activation='relu')(x)\n",
    "    x = Concatenate()([t1, t2, t3])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Bi‑LSTM + Attention\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.2))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = attention_block(x)\n",
    "\n",
    "    # Dense head\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(seq_in, out)\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC','accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_final_model(window_size, len(feature_cols))\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50, batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"\\nTest AUC: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vincent": {
   "sessionId": "69652639ec0b92a909c25a12_2025-04-07T12-41-28-233Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
